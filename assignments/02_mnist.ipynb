{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем первую модель на MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План на сегодня: пишем первый пайплайн для обучения\n",
    "\n",
    "1. Пытаемся понять, какие компоненты нам нужны для обучения любой модели\n",
    "2. Выясняем, что многое уже есть в Pytorch\n",
    "3. Собираем наш первый скрипт для обучения на датасете MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Разбираемся с данными\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Организуем доступ к данным с `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет в pytorch - это объект класса, в котором реализовано два обязательных метода: `__getitem__(self, index: int)` (получение одиночного примера по индексу) и `__len__(self)` (получение общего количества примеров). Этих методов достаточно, чтобы разбивать датасет на минибатчи  - это работу делает класс `torch.utils.DataLoader` с помощью различных семплеров, с ними мы понакомимся позже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10e2d7ed0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0, 1, 2]), tensor(2))\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, n: int) -> None:\n",
    "        super().__init__()\n",
    "        self.data = torch.arange(n * 3).view((n, 3))\n",
    "        self.labels = torch.randint(0, 5, size=(n,))\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "dataset = MyDataset(n=10)\n",
    "print(dataset[0])\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итерируемся по датасету:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0, 1, 2]), tensor(3))\n",
      "(tensor([3, 4, 5]), tensor(4))\n",
      "(tensor([6, 7, 8]), tensor(0))\n",
      "(tensor([ 9, 10, 11]), tensor(4))\n",
      "(tensor([12, 13, 14]), tensor(1))\n",
      "(tensor([15, 16, 17]), tensor(2))\n",
      "(tensor([18, 19, 20]), tensor(0))\n",
      "(tensor([21, 22, 23]), tensor(0))\n",
      "(tensor([24, 25, 26]), tensor(2))\n",
      "(tensor([27, 28, 29]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(10)\n",
    "for i in range(len(dataset)):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Пакуем данные в батчи с `torch.utils.data.Dataloader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У `torch.utils.data.Dataloader` много аргументов, на практике чаще всего используются\n",
    "- `dataset` - объект, поддерживающий методы `__getitem__` и `__len__` (вопрос: можно ли передать список? словарь? множество?)\n",
    "- `batch_size` - размер мини-батча\n",
    "- `shuffle` - нужно ли перетасовать индексы перед нарезкой на минибатчи (это всегда стоит делать с обучающими данными, почему?)\n",
    "- `num_workers` - количество процессов, которые будут загружать данные - иногда позволяет ускорить обучение (подумайте, в каком случае?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "my_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    # drop_last=\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 25, 26],\n",
      "        [ 6,  7,  8],\n",
      "        [21, 22, 23],\n",
      "        [15, 16, 17]])\n",
      "tensor([2, 0, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(my_loader):\n",
    "    x, y = batch\n",
    "    if i == 0:\n",
    "        print(x)\n",
    "        print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Посмотрим на MNIST\n",
    "\n",
    "- какие атрибуты есть у объекта `torchvision.datasets.MNIST`?\n",
    "- как выглядит одно наблюдение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    \"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),  # что это?\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    \"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(train_dataset, Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "x, y = train_dataset[0]\n",
    "print(x.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1 (1 балл)**. Используя `matplotlib`, выведите по одному примеру изображения для всех классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "examples = {i: None for i in range(10)}\n",
    "\n",
    "for img, label in train_dataset:\n",
    "    if examples[label] is None:\n",
    "        examples[label] = img\n",
    "    if None not in examples.values():\n",
    "        break\n",
    "\n",
    "fig, axes = plt.subplots(1, 10, figsize=(15, 3))\n",
    "for i, (label, img) in enumerate(examples.items()):\n",
    "    axes[i].imshow(img.squeeze(), cmap=\"gray\")\n",
    "    axes[i].set_title(f'Label: {label}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем получить минибатч:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что возвращает `iter()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "batch: tuple[torch.Tensor, torch.Tensor] = next(iter(train_loader))\n",
    "x, y = batch\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Со свёрточными сетями мы познакомимся позже, сейчас же мы будем экспериментировать с обычными полносвязными сетями, но для этого нам нужно будет преобразовать форму батча из `(batch_size, channels, width, height)` в `(batch_size, channels * width * height)`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (1 балл)**. Есть несколько способов изменить форму (shape) тензора. Приведите все знаковые вам способы привести батч с изображениями в форму `(batch_size, channels * width * height)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, channels, width, height = x.shape\n",
    "input_dim = channels * width * height\n",
    "\n",
    "x_reshaped_1 = x.view(batch_size, -1)\n",
    "x_reshaped_2 = x.reshape(batch_size, -1)\n",
    "x_reshaped_3 = x.flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура, с данными вроде разобрались! Теперь разберёмся с моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Реализуем модель с помощью `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Описываем параметры модели и прямой проход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты будем строить небольшую нейронку из двух полносвязных слоёв и `tanh` в качестве функции активации.\n",
    "\n",
    "$\\text{logits} = w_2^T(\\tanh(w_1^T x + b_1)) + b_2$\n",
    "\n",
    "Какие параметры должны быть в линейном слое?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x2897c3280>\n",
      "torch.Size([4, 128])\n",
      "<AddBackward0 object at 0x2896f0c10>\n",
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 128  # размерность скрытого слоя\n",
    "n_classes = 10\n",
    "\n",
    "# первый слой\n",
    "w1 = torch.randn((input_dim, hidden_dim), requires_grad=True)\n",
    "b1 = torch.randn(hidden_dim, requires_grad=True)\n",
    "\n",
    "# второй слой\n",
    "w2 = torch.randn((hidden_dim, n_classes), requires_grad=True)\n",
    "b2 = torch.randn(n_classes, requires_grad=True)\n",
    "\n",
    "h = x.flatten(1) @ w1 + b1\n",
    "print(h.grad_fn)\n",
    "print(h.shape)\n",
    "\n",
    "# применяем нелинейность перед применением следующего слоя\n",
    "h = h.tanh()\n",
    "\n",
    "h = h @ w2 + b2\n",
    "print(h.grad_fn)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  6.0172,   7.4072, -20.6861,   8.9256,  -5.4395,  -6.3682,   0.0770,\n",
       "           6.8565, -20.1673,  -9.1324],\n",
       "        [ -8.9641, -15.7704, -12.9448,   2.2937, -24.6292, -14.9430,  -0.0394,\n",
       "          -3.6719, -27.6249,  -9.3068],\n",
       "        [ -4.3937,  -0.6097, -28.6687,   7.9132, -10.3090,  -3.1383, -18.3530,\n",
       "           0.4476, -16.2507, -17.0004],\n",
       "        [ -3.8893,   4.6379,  -6.8515,  10.1379,  -4.4632,   4.5285,  -7.7709,\n",
       "          -2.0474, -12.9890,  -1.3313]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из этих выходных данных нам хотелось бы получить вероятностное распределение над возможными классами, то есть нужно как-то нормализовать эти активации, для этого обычно используется функция `softmax`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0420, 0.2254, 0.0424, 0.1480, 0.1133, 0.0393, 0.0123, 0.0224, 0.2780,\n",
       "        0.0768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randn(10)\n",
    "torch.softmax(z, 0)\n",
    "# zz = torch.exp(z) / torch.exp(z).sum()\n",
    "# zz.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим к нашим данным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8971e-02, 1.5646e-01, 9.8543e-14, 7.1426e-01, 4.1224e-07, 1.6286e-07,\n",
       "         1.0255e-04, 9.0202e-02, 1.6557e-13, 1.0264e-08],\n",
       "        [1.1737e-05, 1.2991e-08, 2.1915e-07, 9.0944e-01, 1.8462e-12, 2.9712e-08,\n",
       "         8.8208e-02, 2.3332e-03, 9.2312e-14, 8.3315e-06],\n",
       "        [4.5170e-06, 1.9870e-04, 1.2952e-16, 9.9921e-01, 1.2186e-08, 1.5851e-05,\n",
       "         3.9118e-12, 5.7198e-04, 3.2019e-11, 1.5130e-11],\n",
       "        [8.0301e-07, 4.0556e-03, 4.1519e-08, 9.9229e-01, 4.5237e-07, 3.6351e-03,\n",
       "         1.6557e-08, 5.0660e-06, 8.9696e-11, 1.0367e-05]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание: классы получились совсем не равновероятны, хотя мы ещё не учили модель. Подумайте, почему так произошло?\n",
    "Подробнее это мы обсудим на следующей практике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры нашей модели находятся в глобальной области видимости. Решение - спрятать всё внутрь класса-наследника `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Реализуем двуслойный перцептрон как наследник `nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3 (1 балл)**. Прочитайте документацию к классам `torch.nn.Module` и `torch.nn.Parameter`. Почему при задании параметров модели не стоит их создавать просто как `torch.tensor(..., requires_grad=True)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ВАШ ХОД\n",
    "\n",
    "#`torch.nn.Module` и `torch.nn.Parameter` тесно интегрированы. Если задать атрибут модели с использованием `nn.Parameter`, \n",
    "# он автоматически будет включён в список параметров модели, что позволяет корректно передавать его оптимизатору. \n",
    "# В отличие от этого, если просто присвоить атрибуту тензор, \n",
    "# он не будет учтён как параметр модели и не будет обновляться оптимизатором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (1 балл)**. Чтобы сделать наш модуль рабочим, нужно определить два метода: `__init__` и `forward`. Реализуйте метод `forward`, который возвращает логиты, т. е. выход последнего линейного слоя без применения функции активации `softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.w1 = torch.nn.Parameter(torch.randn(input_dim, hidden_dim))\n",
    "        self.b1 = torch.nn.Parameter(torch.randn(hidden_dim))\n",
    "\n",
    "        self.w2 = torch.nn.Parameter(torch.randn(hidden_dim, output_dim))\n",
    "        self.b2 = torch.nn.Parameter(torch.randn(output_dim))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        logits = (x.flatten(1) @ self.w1 + self.b1).tanh() @ self.w2 + self.b2\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleNet(input_dim, hidden_dim, n_classes)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w1',\n",
       "  Parameter containing:\n",
       "  tensor([[-1.2292, -1.0120,  0.4707,  ..., -0.0728, -0.6880, -0.4777],\n",
       "          [ 0.3049, -0.1532, -0.9360,  ..., -0.4225,  1.4490, -1.4940],\n",
       "          [-0.2417,  0.1200,  2.0957,  ..., -1.5898, -0.7208, -0.7473],\n",
       "          ...,\n",
       "          [ 1.0767,  0.5517, -0.3984,  ..., -1.2501, -0.5982,  1.5680],\n",
       "          [-0.8215,  0.8184, -1.3175,  ..., -0.2640,  1.2872, -2.1384],\n",
       "          [-0.9900,  0.2295, -0.0511,  ...,  1.2163, -0.0432,  0.2473]],\n",
       "         requires_grad=True)),\n",
       " ('b1',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0455, -0.4694, -0.6163, -0.9565,  0.9412, -2.0597,  0.8542, -1.0297,\n",
       "          -0.4305, -0.0911, -0.0372,  0.9671,  0.3460, -0.2004,  1.2349, -0.2132,\n",
       "           0.3037,  0.6809, -1.4601, -2.1847, -1.1509,  0.6184,  0.1307,  0.6123,\n",
       "           0.4117,  0.5679, -1.0337,  1.2653, -1.4532, -0.0134,  0.0051,  0.3899,\n",
       "           1.4850, -0.2099, -1.0838, -0.2242, -0.7229,  0.0957,  0.8528, -1.3629,\n",
       "           0.2486,  0.4181,  0.9491,  1.0454,  1.0737, -1.9635,  0.0171,  0.9307,\n",
       "          -0.2122,  0.0204,  0.5377, -0.5969,  1.2541,  0.0887, -0.3743, -0.2694,\n",
       "          -0.6991,  0.0542, -1.4888,  0.7427,  0.7323, -1.2028,  0.2734,  0.6461,\n",
       "           0.1553,  1.4138, -0.3121, -0.2429, -0.6519, -0.6571, -0.2563, -1.2612,\n",
       "          -1.0530, -0.9300, -0.1610, -0.1113, -0.3058, -1.8905,  0.4953, -0.3963,\n",
       "          -1.6818,  0.3714,  0.6923,  0.5177, -0.5238,  0.3190, -0.1159, -0.5549,\n",
       "          -1.1374, -0.0827, -0.3218,  0.0387, -0.2934,  0.2791, -0.7186, -1.4691,\n",
       "           0.1718, -0.6585, -1.0450, -0.9719, -1.0089, -0.4989, -0.8218,  1.0611,\n",
       "           0.5773, -1.0302,  0.8653, -0.8490, -0.3620, -1.9474,  1.0786,  0.5214,\n",
       "           0.2878,  0.9044, -0.2266, -0.1701, -0.0971, -1.4061,  1.4639, -0.5262,\n",
       "           1.2787,  2.0971, -1.4370, -0.6771,  0.9290, -0.0264, -0.0942, -0.8176],\n",
       "         requires_grad=True)),\n",
       " ('w2',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.4460,  0.3349, -0.7410,  ...,  0.0740,  1.6430,  0.5359],\n",
       "          [-2.3654,  0.3553,  0.1256,  ..., -0.0950, -1.8155,  1.2051],\n",
       "          [-0.6183,  0.1571,  0.4559,  ...,  1.2749, -0.9803,  0.4386],\n",
       "          ...,\n",
       "          [-0.0512,  1.3929,  1.5248,  ...,  0.9805,  0.0346, -0.0602],\n",
       "          [ 1.0721, -1.1995,  1.1074,  ..., -0.0248,  0.4186,  1.0637],\n",
       "          [-0.2521, -0.1926,  0.1326,  ...,  1.2250, -0.2569, -0.4325]],\n",
       "         requires_grad=True)),\n",
       " ('b2',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1960, -0.3484, -0.3309,  0.1433, -0.7052, -1.7221, -0.3078,  0.4789,\n",
       "          -0.3878, -0.2103], requires_grad=True))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вручную обновлять значения многих параметров очень неудобно. К счастью, за нас это сделает оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Считаем ошибку и градиенты на одном минибатче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.9353, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# получим предсказания и посчитаем ошибку\n",
    "predictions = model.forward(x)\n",
    "loss = torch.nn.functional.cross_entropy(predictions, y)\n",
    "print(loss)\n",
    "# рассчитаем градиенты и обновим параметры\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# не забудем почистить градиенты, мы не хотим их накапливать\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5 (1 балл)**: Посчитайте значение перекрёстной энтропии самостоятельно по формуле, сверьтесь с результатом выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитайте ce_loss на основе значений переменных `predictions` и `y`\n",
    "# ВАШ ХОД\n",
    "log_probs = torch.nn.functional.log_softmax(predictions, dim=1)\n",
    "true_class_log_probs = log_probs[torch.arange(len(y)), y]\n",
    "ce_loss = -torch.mean(true_class_log_probs)\n",
    "assert torch.allclose(ce_loss, loss), f\"{ce_loss} != {loss}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Шаг обучения: что мы делаем с каждым минибатчем данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(\n",
    "    batch: tuple[torch.Tensor, torch.Tensor],\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    # прогоняем батч через модель\n",
    "    x, y = batch\n",
    "    predictions = model(x)\n",
    "    # оцениваем значение ошибки\n",
    "    loss = torch.nn.functional.cross_entropy(predictions, y)\n",
    "    # обновляем параметры\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    # возвращаем значение функции ошибки для логирования\n",
    "    return loss, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестовых батчей нам не нужны градиенты, поэтому расчёты делаем внутри контекста `torch.no_grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(\n",
    "    batch: tuple[torch.Tensor, torch.Tensor], model: torch.nn.Module\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    x, y = batch\n",
    "    with torch.no_grad():\n",
    "        predictions = model(x)\n",
    "        # оцениваем значение ошибки\n",
    "        loss = torch.nn.functional.cross_entropy(predictions, y)\n",
    "    return loss, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. А теперь: что мы хотим делать в каждой эпохе?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6 (2 балла)**: Напишите функцию для запуска одной эпохи (обучающей или тестовой), которая итерируется по минибатчам, обрабатывает их и в конце выводит среднюю ошибку и точность классификации. Запустите обучение на 10-15 эпох, добейтесь точности более 92% на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(\n",
    "    is_train: bool,\n",
    "    dataloader: DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    ") -> None:\n",
    "    # ВАШ ХОД\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        x, y = batch\n",
    "        \n",
    "        if is_train:\n",
    "            loss, predictions = training_step((x, y), model, optimizer)\n",
    "        else:\n",
    "            loss, predictions = test_step((x, y), model)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        _, predicted_labels = torch.max(predictions, dim=1)\n",
    "        \n",
    "        correct_predictions += (predicted_labels == y).sum().item()\n",
    "        \n",
    "        total_samples += y.size(0)\n",
    "    \n",
    "    epoch_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    print(f\"{'Train' if is_train else 'Test'} - Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим модель, оптимизатор и загрузчики данных и запустим обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train:\n",
      "Train - Loss: 1.5844, Accuracy: 0.7650\n",
      "Epoch 0 test:\n",
      "Test - Loss: 0.7284, Accuracy: 0.8579\n",
      "Epoch 1 train:\n",
      "Train - Loss: 0.6006, Accuracy: 0.8687\n",
      "Epoch 1 test:\n",
      "Test - Loss: 0.5277, Accuracy: 0.8817\n",
      "Epoch 2 train:\n",
      "Train - Loss: 0.4296, Accuracy: 0.8952\n",
      "Epoch 2 test:\n",
      "Test - Loss: 0.4370, Accuracy: 0.8928\n",
      "Epoch 3 train:\n",
      "Train - Loss: 0.3497, Accuracy: 0.9084\n",
      "Epoch 3 test:\n",
      "Test - Loss: 0.3935, Accuracy: 0.8975\n",
      "Epoch 4 train:\n",
      "Train - Loss: 0.3013, Accuracy: 0.9174\n",
      "Epoch 4 test:\n",
      "Test - Loss: 0.3612, Accuracy: 0.9056\n",
      "Epoch 5 train:\n",
      "Train - Loss: 0.2707, Accuracy: 0.9226\n",
      "Epoch 5 test:\n",
      "Test - Loss: 0.3374, Accuracy: 0.9083\n",
      "Epoch 6 train:\n",
      "Train - Loss: 0.2477, Accuracy: 0.9290\n",
      "Epoch 6 test:\n",
      "Test - Loss: 0.3265, Accuracy: 0.9103\n",
      "Epoch 7 train:\n",
      "Train - Loss: 0.2308, Accuracy: 0.9325\n",
      "Epoch 7 test:\n",
      "Test - Loss: 0.3104, Accuracy: 0.9127\n",
      "Epoch 8 train:\n",
      "Train - Loss: 0.2165, Accuracy: 0.9370\n",
      "Epoch 8 test:\n",
      "Test - Loss: 0.3003, Accuracy: 0.9161\n",
      "Epoch 9 train:\n",
      "Train - Loss: 0.2050, Accuracy: 0.9396\n",
      "Epoch 9 test:\n",
      "Test - Loss: 0.2915, Accuracy: 0.9182\n",
      "Epoch 10 train:\n",
      "Train - Loss: 0.1951, Accuracy: 0.9420\n",
      "Epoch 10 test:\n",
      "Test - Loss: 0.2887, Accuracy: 0.9188\n",
      "Epoch 11 train:\n",
      "Train - Loss: 0.1863, Accuracy: 0.9447\n",
      "Epoch 11 test:\n",
      "Test - Loss: 0.2776, Accuracy: 0.9219\n",
      "Epoch 12 train:\n",
      "Train - Loss: 0.1787, Accuracy: 0.9467\n",
      "Epoch 12 test:\n",
      "Test - Loss: 0.2725, Accuracy: 0.9239\n",
      "Epoch 13 train:\n",
      "Train - Loss: 0.1717, Accuracy: 0.9489\n",
      "Epoch 13 test:\n",
      "Test - Loss: 0.2749, Accuracy: 0.9251\n",
      "Epoch 14 train:\n",
      "Train - Loss: 0.1655, Accuracy: 0.9502\n",
      "Epoch 14 test:\n",
      "Test - Loss: 0.2686, Accuracy: 0.9245\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Epoch {i} train:\")\n",
    "    run_epoch(True, train_loader, model, optimizer)\n",
    "    print(f\"Epoch {i} test:\")\n",
    "    run_epoch(False, test_loader, model, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
